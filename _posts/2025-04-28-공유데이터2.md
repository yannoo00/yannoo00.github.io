---
title:  "공유데이터 동기화 - Lock"
layout: post
excerpt: "Lock"

categories:
  - Network
tags:
  - [Network]

toc: true
toc_sticky: true
 
date: 2025-04-29
last_modified_at: 2025-04-30
---

<br>

## 공유 데이터의 동기화 문제 - Lock 기초

```cpp

//
#include "pch.h"
#include <iostream>
#include "CorePch.h"

#include <thread>
#include <atomic> //atomic: All or nothing
#include <mutex>

using namespace std;

vector<int32> v; //container 자료구조라고 하자.
mutex m; //자물쇠(occupied)

// RAII pattern(Resource Acquisition is initialization)
template<typename T>
class LockGuard
{
public:
    LockGuard(T& m)
    {
        _mutex = &m;
        _mutex->lock();
    }

    ~LockGuard()
    {
        _mutex->unlock();
    }
};

void Push()
{
    for (int32 i = 0; i < 10'000; ++i)
    {
        LockGuard<mutex> lockGuard(m);

        m.lock();
        
        v.push_back(i);

        m.unlock();
        
    }
}


int main()
{
    
    thread t1(Push);
    thread t2(Push);
    
    t1.join();
    t2.join();
    
    cout << v.size() << endl;
}


```

공유 데이터일 때에도 원자적 계산을 보장하는 Atomic 선언은 편리하지만  
자료형 개념이기 때문에 atomic형으로 vector를 만들어서 push 연산을 활용하거나 할 수는 없다.  

공유 데이터 접근을 제한하는 또 다른 방법으로,  
하나의 변수가 아니라 공유 데이터에 대한 접근을 제한할 수 있는 mutex가 존재한다.  

위처럼 mutex->lock()을 사용하면 unlock이 될 때까지 공유 데이터에 접근할 수 없다.   
따라서 vector에 10,000개의 push가 온전히 이뤄짐을 보장한다.  

이를 보면 무척 편리하지만 unlock을 실수로 안해줬을 때 사고가 발생할 수 있음을 알 수 있다...  
동적할당을 해제하지 않아 발생하는 memory leak과 비슷한 방식으로  
lock을 걸었다면 반드시 unlock을 해줘야 하고, 중간에 들어오는 탈출문이나 기타 여러 함수 호출 등으로 인해 unlock을 건너뛰게 될 수도 있다.  

이런 상황을 방지하기 위해 LockGuard class를 만든 것처럼 (lock_guard가 library로 존재함) 소멸 시에 lock 해제를 보장하는 방식 등으로 unlock을 보장하게 만들어 사용해야 한다.  

<br>
<br>

### Dead Lock 

데드락은 두 개 이상의 프로세스나 스레드가 서로 상대방이 점유한 자원을 기다리며 무한정 대기하는 상황을 말한다.  

예를 들어, lock을 거는 객체가 2개인 상황을 생각해보자.  
```cpp
class ResourceA {
public:
    ResourceA() {
        lock_guard<mutex> lock(mtx);  // A의 뮤텍스 획득
        // TODO
    }
    mutex mtx;
};

class ResourceB {
public:
    ResourceB() {
        lock_guard<mutex> lock(mtx);  // B의 뮤텍스 획득
        // TODO
    }
    mutex mtx;
};
```
이 두 클래스를 같이 사용하는 과정에서, 스레드 1이 A를 lock하고 B를 기다리고  
스레드 2는 B를 lock 하고 A를 기다리며 무한정 대기하는 상황이 발생할 수 있다.  

이 문제를 해결하기 위한 방법 중 하나로, lock을 거는 순서를 정해줄 수 있다.  
mutex를 class로 만들고 매핑을 통해 id가 반드시 더 큰 뮤텍스가 나중에 수행되게 한다든지 하는 식으로 ...   
순서가 원인으로 dead lock이 발생한다면 lock 잡는 순서를 그래프로 표현했을 때 cycle이 생기는 상황인 것으로 이해하고 그 cycle을 감지하는 알고리즘으로 방지할 수도 있다.  

하지만 무슨 방법이든 데드락을 100% 막는다는 보장은 할 수 없다.  
서버 접속 시에 엄~청 오래 대기하다가 Time out이 발생하면서 튕기는 경험이 많이 있는데  
데드락 대응으로 타임아웃을 설정해둔 것이 아니었을까?

<br>
<br>
<br>

참고: _인프런 Rookiss_