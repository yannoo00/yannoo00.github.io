---
title:  "MinHash와 LSH 알고리즘"
layout: post
excerpt: "MinHash와 LSH 알고리즘"

categories:
  - algorithm
tags:
  - [algorithm]

toc: true
toc_sticky: true
 
date: 2026-01-10
last_modified_at: 2026-01-10
---


## Min Hash와 Locality Sensitive Hashing(LSH)  

Min Hash와 Locality Sensitive Hashing 두 알고리즘을 조합하면 대규모 데이터의 유사도 비교를 효과적으로 할 수 있다.  Min Hash가 같을 확률은 Jaccard Index 값과 유사하기 때문이다.  
Min Hash로 긴 값을 해싱하여 압축하고, 이 값을 비교하여 Localisth Sensitive Hasing으로 유사한 것들끼리 모이게 되는 bucket에 나눠 담는다. 그 후 bucket 내부에서만 고비용의 실제 비교 연산을 수행하면 '유사도가 높을 가능성이 있는 후보들'에 대해서만 효율적으로 비교하는 것이 가능하다.  



### 이 알고리즘을 사용하게 된 이유  

업무 중 대규모 string들의 유사도를 계산해야 할 일이 있었다.  
내가 하고 싶었던 것은 평균 length ~= 1,000 정도의 문자열 20,000여개의 Jaccard Index를 계산하여,  
그 값이 큰 요소끼리 같은 군집으로 묶는 것이다.  

가장 단순한 알고리즘(=brute force)으로 먼저 생각해보자.  

length 1000의 문자열 20000개니까, 20,000,000 문자를 서로 비교해야한다.  
두 문자열을 가장 무식하게 비교하는 방법은 N*N으로 하나씩 직접 비교하는 것이다.  

모든 쌍에 대한 모든 문자열을 계산한다면 대략 (20000 * 20000) * (1000 * 1000)번의 연산이 발생한다. => 아주 오래걸린다.  

이미 문자 수 자체로 수천만, 억에 가까워진 상황에서 N^2번의 연산은 수행하기 어렵다.  
일회성 분석이라면 상관 없지만 그게 아니라면 O(N)에 가까운 성능으로 분석을 마칠 수 있어야 활용이 가능했다.  
물론 문자열 비교 자체를 더 효율적으로 구현할 수 있지만 N*N 쌍 자체를 줄일 수 있을 것 같았다.  

그래서, 무작정 모든 쌍의 문자열에 대해 문자열 비교를 통해 유사도 계산을 수행하는 것이 아니라 가능성이 있는 후보들만 추출하여 그들 끼리 비교연산을 수행할 수 있는 방법을 찾게 되었다.  





### Min Hash 

Min Hash는 자카드 유사도(교집합/합집합)를 빠르고 적은 용량으로 계산할 수 있다. 
일단 해시 알고리즘이므로, 긴 문자열을 고정된 길이의 숫자로 압축한다.  

진행 단계는 다음과 같다.  

1. Shingling(전처리)  
텍스트를 잘라서 작은 조각의 집합으로 만든다. 보통 n-gram을 활용한다.  
n=2일 때를 예를 들면 "1234" 라는 문자열이 있을 때 "12", "23", "34"로 나뉘는 식이다.  
이 단계는 데이터 성격, 분석 목적에 따라 달라질 수 있다.  
중요한 것은 구성요소를 나누어서 각각에 대해 hash function을 적용할 수 있는 형태로 만드는 것이다.  
데이터 셋에서 순서가 중요하다면 12, 23, 34 이렇게 묶어서 hash를 적용하는게 유의미할 수 있고  
만약 1, 2 각각의 포함 여부 자체만 중요하다면 set = {1, 2, ... } 이렇게 각각을 고유하게 담은 자료형에서 하나씩 뽑아 hash function을 적용하는게 더 유리할 것이다.  

2. Hasing  
이렇게 나눈 조각들에 대해 해시 값을 부여한다.  
minhash는 각 조각들에 대해 hash function을 적용하고, 그렇게 나온 값들 중 min 값을 뽑는다.  
즉 1번 과정에서 분리한 조각이 몇 개든 상관 없이, 그 전체에 대해 hash function을 적용하고 최종 결과를 min값 하나만을 추출한다.  

이 과정을 n개의 gram 덩어리를 가지는 m 개의 모든 문자열에 대해 적용하는 것이다.  
그리고 같은 해시값 min을 추출한 결과가 같은 두 문자열이 있다면?  
그 문자열들은 같은 문자(gram)를 가지는 확률이 높다고 보는 것이다.  

값이 같았을 때 마다 두 문자열의 유사도는 1/(해시함수 수행횟수), 2/(해시함수 수행횟수), ... 이렇게 늘어날 것이다.  
즉 충분히 타당한 유사도를 확보하기 위해서는 다양한 해시 함수로 여러번 계산하는 과정이 필요하다.  


이렇게 조각낸 문자열들에 대해 해시 함수를 적용하고 추출한 최솟값이 같을 확률이 Jaccard index 값과 거의 같다고 본다.  



### Locality Sensitive Hashing(LSH)  

MinHash로 문자열 비교 과정을 압축할 수는 있지만, 여전히 그렇게 압축한 해시값을 n*n번 비교해야한다는 문제가 남는다.  

이 때 LSH는 비슷할 가능성이 있는 대상들만 같은 bucket에 담는 방식으로 전체 비교 횟수를 줄인다.  

비슷할 가능성은 어떻게 측정할까?  
LSH는 band 값을 설정하고, band 단위로 해시값을 모아 테이블을 구성한다. 그 band 단위로 모인 해시 값이 모두 같은 문자열들은 같은 bucket에 들어간다.  

더 자세히 예를 들면,  
band 길이가 4인 상황에서 문자열 A에 해시를 적용한 결과가 band1 = [1, 3, 9, 7], band2 = [2, 4, 5, 10] 이라고 하자.  
문자 B는 band1 = [1, 3, 9, 12321], band2 = [2, 4, 5, 10]이다.  
이런 경우 band1의 비교에서는 A와 B가 같은 bucket에 들어갈 수 없지만 band2의 값이 모두 같으므로 일단 같은 bucket에 들어가게 되는 것이다.  

이렇게 하나의 band라도 같으면 실제 비교 후보군이 되므로 전혀 비슷할 가능성이 없는 문자열들을 비교하는 낭비를 줄일 수 있다.  
band 길이를 늘릴수록 더 깐깐하게 비교하게 되므로 후보군으로 잡히는 문자열의 개수가 줄어들 것이다.  
반면 band의 개수 자체가 많아진다면 (=band 하나의 길이가 줄어든다) 더 널널하게 후보군으로 넣게 된다.  
즉 (band개수) * (band길이) = (minHash에서 사용한 함수 개수)가 되도록, 이 값들을 원하는 기준에 맞게 조절해볼 수 있다.

처음엔 *** 결국 모든 band에 들어있는 모든 값을 살펴보면서 비교해야하므로 결국 모든 문자열에 대해 n * n의 비교가 발새생하는 것 아닌가? ***  
라고 오해했는데, 그게 아니라 각 band에 다시 hash를 적용하여 그 결과값과 매칭되는 bucket에 그 문자열을 담는 것이다.  
따라서 한 문자열이 여러개의 bucket에서 등장할 것이다. 그 안에서 자기들끼리 비교하고 유사도가 특정 값을 넘으면 같은 군집으로 배속하면 된다. 이 때는 Union-Find를 활용할 수 있다.  










<br>
